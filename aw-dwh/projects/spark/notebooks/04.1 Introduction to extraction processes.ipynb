{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab56999-648c-48e4-a6c3-aab4d71bc6de",
   "metadata": {},
   "source": [
    "# 04.1 Introduction to extraction processes\n",
    "\n",
    "The goal of this laboratory session is for you to implement and orchestrate extraction processes for the AdventureWorks data warehouse.\n",
    "\n",
    "First lets recall the available data sources:\n",
    "\n",
    "- AdventureWorks Core (MySQL)\n",
    "- AdventureWorks HR Files (HTTP Server)\n",
    "- AdventureWorks Reviews API (REST API)                                                                            - \n",
    "\n",
    "Each of the sources is of a different kind and will require a specific approach to be able to extract the data from it.\n",
    "                                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe38069-7f90-4815-a80b-f5145c3572a4",
   "metadata": {},
   "source": [
    "## 1. Resources for extracting data from a MySQL database\n",
    "\n",
    "Most of the existent databases require an special driver (connector) to communicate with them. In this case we installed the driver for MySQL during the image creation process in the Dockerfile (`aw-dwh/config/aio/dockerfile`)\n",
    "\n",
    "```\n",
    "# Download and install MySQL JDBC driver\n",
    "RUN curl -L -o /opt/spark/jars/mysql-connector-j-${MYSQL_VERSION}.jar \\\n",
    "    \"https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/${MYSQL_VERSION}/mysql-connector-j-${MYSQL_VERSION}.jar\" \n",
    "```\n",
    "\n",
    "Having the driver installed we defined a Dagster resource to represent a MySQL database, remember from the previous lab that a Dagster resource should always represent an external service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff5195-5604-44ad-8497-53d00896078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySQLResource(ConfigurableResource, ABC):\n",
    "    \n",
    "    host: str = Field(description=\"The hostname or IP address of the MySQL server.\")\n",
    "    port: str = Field(description=\"The port on which the MySQL server is listening, defaults to 3306.\")\n",
    "    database: str = Field(description=\"The name of the MySQL database to connect to.\")\n",
    "    user: str = Field(description=\"The username for authenticating with the MySQL server.\")\n",
    "    password: str = Field(description=\"The password associated with the given username.\")\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fetch_table(self, table_name: str) -> Any:\n",
    "        pass\n",
    "\n",
    "    def _get_connection_string(self) -> str:\n",
    "        return f\"jdbc:mysql://{self.host}:{self.port}/{self.database}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb326a0-07dc-42ff-a18f-4a92a40c497a",
   "metadata": {},
   "source": [
    "The `MySQLResource` class receives in its constructor the database credentials and its able to build a connection string for the database.\n",
    "\n",
    "Also there is an abstract method `fetch_table` to customize the way we extract the data from the table. In this case we used PySpark to extract the data from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb48a7-44da-4c6b-af53-14c1b4fee4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PySparkMySQLResource(MySQLResource):\n",
    "\n",
    "    pyspark: ResourceDependency[PySparkResource]\n",
    "\n",
    "    def fetch_table(self, table_name: str) -> DataFrame:\n",
    "        df = self.pyspark.spark_session.read.jdbc(\n",
    "            url=self._get_connection_string(), # the connection string\n",
    "            table=table_name,\n",
    "            properties={\n",
    "                \"user\": self.user,\n",
    "                \"password\": self.password,\n",
    "                \"driver\": \"com.mysql.cj.jdbc.Driver\", # this specifies the driver for the connection\n",
    "                \"fetchSize\": \"10000\" # this specifies how many rows we extract at a time\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c951c5-db16-4d8a-b885-3ab79c86a6a5",
   "metadata": {},
   "source": [
    "## 2. Defining the assets\n",
    "\n",
    "To hold the assets code we created a `landing` folder within the assets folder, remember that this folder must be a module so we also created a `__init__.py` file.\n",
    "\n",
    "To define all the AdventureWorks Core (MySQL) assets we created the `aw_core_mysql.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5270fd-83b7-4c2c-817b-9a088365d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dagster as dg\n",
    "from adventureworks_orchestration.resources.mysql_resource import MySQLResource\n",
    "from adventureworks_orchestration.constants import *\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "\n",
    "# You can also dinamically define your assets, unlike a multi asset dinamically defined assets\n",
    "# support native parallelism \n",
    "\n",
    "aw_core_tables = [] # ???\n",
    "\n",
    "def get_landing_aw_core_table_asset(table: str):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def get_bronze_aw_core_assets():\n",
    "    return [get_landing_aw_core_table_asset(table) for table in aw_core_tables]\n",
    "\n",
    "\n",
    "ASSETS = get_bronze_aw_core_assets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d528b5-df9e-436e-a2ee-bef9de5e70a6",
   "metadata": {},
   "source": [
    "This file follows a different approach to declare the assets that the one we used in the previous lab. In this case we defined a `get_landing_aw_core_table_asset` method that given a table constructs its corresponding assets. Then we build the assets for all tables and declared them as a constant in the file.\n",
    "\n",
    "Don't forget to register your new assets in the `definitions.py` file!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
